{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1、经典的代码实现过程."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 定义硬件GPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 原始数据加载\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# DataLoader定义\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 模型定义\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)  # 输入1个通道，输出32个通道，卷积核5x5\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)  # 输入32个通道，输出64个通道\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 128)  # 64个通道，经过2次卷积后尺寸缩小为4x4\n",
    "        self.fc2 = nn.Linear(128, 10)  # 输出10类\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 64 * 4 * 4)  # 展平\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN().to(device)\n",
    "\n",
    "# 损失函数与优化器定义\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# 训练集循环\n",
    "num_epochs = 5\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # 清零梯度\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 前向传播 + 反向传播 + 优化\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "# 学习曲线绘制\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 模型保存与加载\n",
    "torch.save(model.state_dict(), 'mnist_cnn.pth')\n",
    "print(\"Model saved as mnist_cnn.pth\")\n",
    "\n",
    "# 模型推理\n",
    "model.load_state_dict(torch.load('mnist_cnn.pth'))\n",
    "model.eval()  # 设置模型为评估模式\n",
    "\n",
    "# 测试推理\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2、定义一个config配置文件-指定相关参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要将超参数如 `batch_size` 等设置写到一个配置文件中，可以使用多种格式，例如 YAML、JSON 或 INI 文件。这里，我们将使用 YAML 格式来定义一个配置文件，并展示如何在 PyTorch 中读取该配置文件。\n",
    "\n",
    "### 第一步：创建 YAML 配置文件\n",
    "\n",
    "创建一个名为 `config.yaml` 的文件并写入以下内容：\n",
    "\n",
    "```yaml\n",
    "# config.yaml\n",
    "training:\n",
    "  batch_size: 64\n",
    "  num_epochs: 10\n",
    "  learning_rate: 0.01\n",
    "  momentum: 0.9\n",
    "\n",
    "data:\n",
    "  data_root: './data'\n",
    "  num_workers: 4\n",
    "\n",
    "model:\n",
    "  input_channels: 1\n",
    "  num_classes: 10\n",
    "```\n",
    "\n",
    "### 第二步：在 Python 中读取 YAML 配置文件\n",
    "\n",
    "使用 `PyYAML` 库读取配置文件。在 Python 脚本中，首先确保安装 `PyYAML`：\n",
    "\n",
    "```bash\n",
    "pip install pyyaml\n",
    "```\n",
    "\n",
    "然后可以使用以下代码读取配置文件并访问超参数：\n",
    "\n",
    "```python\n",
    "import yaml\n",
    "\n",
    "# 读取 YAML 配置文件\n",
    "with open('config.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# 访问参数\n",
    "batch_size = config['training']['batch_size']\n",
    "num_epochs = config['training']['num_epochs']\n",
    "learning_rate = config['training']['learning_rate']\n",
    "momentum = config['training']['momentum']\n",
    "data_root = config['data']['data_root']\n",
    "num_workers = config['data']['num_workers']\n",
    "input_channels = config['model']['input_channels']\n",
    "num_classes = config['model']['num_classes']\n",
    "\n",
    "print(f'Batch Size: {batch_size}')\n",
    "print(f'Num Epochs: {num_epochs}')\n",
    "print(f'Learning Rate: {learning_rate}')\n",
    "print(f'Momentum: {momentum}')\n",
    "print(f'Data Root: {data_root}')\n",
    "print(f'Num Workers: {num_workers}')\n",
    "print(f'Input Channels: {input_channels}')\n",
    "print(f'Num Classes: {num_classes}')\n",
    "```\n",
    "\n",
    "### 第三步：在 PyTorch 中使用超参数\n",
    "\n",
    "在训练循环或模型定义中使用这些从配置文件中读取的超参数。例如：\n",
    "\n",
    "```python\n",
    "# 使用配置中的超参数创建数据加载器\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "\n",
    "# 使用这些超参数进行训练\n",
    "for epoch in range(num_epochs):\n",
    "    # 训练过程\n",
    "```\n",
    "\n",
    "### 总结\n",
    "通过将超参数保存在配置文件中，可以更轻松地管理和调整这些参数，而不需要在代码中直接修改。这使得代码更加灵活和可维护。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主程序部分.\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "\n",
    "# 读取 YAML 配置文件\n",
    "with open('config.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "# 超参数\n",
    "batch_size = config['training']['batch_size']\n",
    "num_epochs = config['training']['num_epochs']\n",
    "learning_rate = config['training']['learning_rate']\n",
    "momentum = config['training']['momentum']\n",
    "num_workers = config['data']['num_workers']\n",
    "\n",
    "# 定义硬件GPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 原始数据加载\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root=config['data']['data_root'], train=True, download=True, transform=transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root=config['data']['data_root'], train=False, download=True, transform=transform)\n",
    "\n",
    "# DataLoader定义\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "# 模型定义\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(64 * 4 * 4, 128)  # 经过卷积和池化后的输出大小\n",
    "        self.fc2 = nn.Linear(128, config['model']['num_classes'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 64 * 4 * 4)  # 展平\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "model = SimpleCNN().to(device)\n",
    "\n",
    "# 损失函数与优化器定义\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "# 训练集循环\n",
    "train_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # 清零梯度\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 前向传播 + 反向传播 + 优化\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(avg_loss)\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "# 学习曲线绘制\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 模型保存与加载\n",
    "torch.save(model.state_dict(), 'mnist_cnn.pth')\n",
    "print(\"Model saved as mnist_cnn.pth\")\n",
    "\n",
    "# 模型推理\n",
    "model.load_state_dict(torch.load('mnist_cnn.pth'))\n",
    "model.eval()  # 设置模型为评估模式\n",
    "\n",
    "# 测试推理\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy of the network on the 10000 test images: {100 * correct / total:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xy_ultra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
